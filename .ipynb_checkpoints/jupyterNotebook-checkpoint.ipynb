{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a744eeac",
   "metadata": {},
   "source": [
    "# Introduction, Motivation and/or Problem Statement "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7075d6b4",
   "metadata": {},
   "source": [
    "The ability of an AI to play video games comparably to a human, has been a great interest in the AI community. AI has managed to succeed in a wide variety of games, but in a lot of cases the AI is directly fed in the data rather than obtaining it through what's shown on the screen. As such, these AI models do not accurately reflect a human player, since they have access to exact data values and information which a human player would be unable to infer from looking at the screen. However, https://arxiv.org/pdf/1312.5602.pdf, showed that the game Atari Breakout was playable by a deep learning model which inferred all the information needed directly from the screen through the use of a CNN. This type of model is a better representation of an AI playing a game in the same way a human player would. \n",
    "\n",
    "The game Flappy Bird has been a popular choice for the testing of new deep learning models which are designed for games. These models fall under the area of reinforcement learning. When training reinforcement learning models in game-playing capabilities, a common trend is to utilise genetic models such as the NEAT algorithm, Experience replay models like Deep Q-Learning or model-free methods such as Q-Learning. Many of these methods require a direct tap into the variables of the game and as a result, rely on self-implementations that don’t directly reflect the true state of the game. Furthermore, a model knowing the exact values of variables isn’t reflective of a human player playing the game.  \n",
    "\n",
    "As a result, the aim of this paper is to implement a model that utilises CNN classification techniques alongside the game ‘Flappy Bird’ to identify game objects, and provide data to another algorithm for Reinforced Learning. This should allow the model to be used on any implementation of ‘Flappy Bird’, regardless of game screen size or implementation specific variables, giving the implementation an edge over other models in applicability. Also, a CNN gathering information from the pixels is better representative of a human player, who acts solely based on what’s shown on the screen. From prior research, it has been hypothesised that the Deep Q-Learning model, with its capability to generalise actions over large datasets will be the most suitable approach to combine with this CNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acf4532",
   "metadata": {},
   "source": [
    "# Data Sources or RL Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a730223f",
   "metadata": {},
   "source": [
    "The task is to teach a model to play the game of flappy bird perfectly. The flappy bird game involves a bird which is usually controlled by a human player. The bird has 1 action which it can take, *flap*, which causes the bird to increase its height and stop it from falling temporarily. There are also a sequence of vertical pipe pairs which are seperated by a gap and the player receives a score point if the bird can fly through the gap without hitting the pipes. If the bird flies into one of the pipes or hits the ground, the player loses. The goal of the game is to fly as long as possible through the pipe gaps and get the highest score without colliding with the pipes or ground. This is summarised in the images below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8bda88",
   "metadata": {},
   "source": [
    "<img src=\"./notebook_assets/trainingBird.gif\" width=\"200\" height=\"400\" />\n",
    "\n",
    "<em>Training Bird</em>\n",
    "\n",
    "<img src=\"./notebook_assets/Flappybird.gif\" width=\"700\" height=\"400\" />\n",
    "\n",
    "<em>Trained Bird</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb969ae",
   "metadata": {},
   "source": [
    "Most deep learning model attempts at Flappy Bird rely on the input data being directly provided to the model. However, there has been attempts at using a CNN to infer the data from the screen. Github user yenchenlin (https://github.com/yenchenlin/DeepLearningFlappyBird), built a working implementation of a CNN + QLearning model which is able to play the game. However, it should be noted that in his implementation, the game is quite forgiving. This implementation has lower pipe velocity and slower bird movement, allowing for the model to make a mistake without dying. This however isn't an accurate representation of the Flappy Bird game, which was originally quite fast paced. So, in order to preserve accuracy, we decided to make the game as difficult as the original game, keeping a high pipe velocity and quick bird movements. As a result, if the model makes a single mistake it will always lose.\n",
    "\n",
    "The game can be played by running the next 5 cells if the image assets are given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "332f331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bird:\n",
    "    def __init__(self):\n",
    "        self.vel = 0\n",
    "        self.x = BIRD_SIZE\n",
    "        self.y = SCREEN_HEIGHT // 2 - 25\n",
    "        self.tick_count = 0\n",
    "\n",
    "    def move_bird(self):\n",
    "        self.vel += GRAVITY\n",
    "        self.y += self.vel\n",
    "\n",
    "    def flap(self):\n",
    "        self.vel = -10.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f650044",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'neat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-6f84b69ee9ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpygame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mneat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'neat'"
     ]
    }
   ],
   "source": [
    "import pygame\n",
    "import random\n",
    "import neat\n",
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "\n",
    "SCREEN_WIDTH = 550\n",
    "SCREEN_HEIGHT = 850\n",
    "BIRD_SIZE = 50\n",
    "PIPE_WIDTH = 75\n",
    "GAP_SIZE = 200\n",
    "PIPE_HEIGHT = PIPE_WIDTH * 854 / 52\n",
    "VISUALISE = True\n",
    "MAX_FRAME_RATE = 60\n",
    "FITNESS_THRESHOLD = 100\n",
    "GRAVITY = 0.6\n",
    "\n",
    "\n",
    "pipe_img = pygame.transform.scale(pygame.image.load(os.path.join(\"imgs\",\"pipe.png\")).convert_alpha(), (PIPE_WIDTH, PIPE_HEIGHT))\n",
    "bg_img = pygame.transform.scale(pygame.image.load(os.path.join(\"imgs\",\"bg.png\")).convert_alpha(), (600, 900))\n",
    "bird_img = pygame.transform.scale(pygame.image.load(os.path.join(\"imgs\",\"bird1.png\")).convert_alpha(), (BIRD_SIZE, BIRD_SIZE))\n",
    "base_img = pygame.transform.scale2x(pygame.image.load(os.path.join(\"imgs\",\"base.png\")).convert_alpha())\n",
    "screenshots = torch.empty(0,3,600,800)\n",
    "frames = []\n",
    "output = []\n",
    "outputs = torch.empty(0,3)\n",
    "moved = False\n",
    "\n",
    "class Game:\n",
    "    def __init__(self, screen):\n",
    "        self.screen = screen\n",
    "        self.clock = pygame.time.Clock()\n",
    "        self.bird = Bird()\n",
    "        self.pipe_height1 = random.randint(100, 400)\n",
    "        self.pipe_x1 = SCREEN_WIDTH\n",
    "        self.pipe_height2 = random.randint(100, 400)\n",
    "        # manually found starting value for x2 for pipes to be equidistant\n",
    "        self.pipe_x2 = 1.5 * SCREEN_WIDTH + 40\n",
    "        self.score = 0\n",
    "\n",
    "    def move_pipes(self):\n",
    "        self.pipe_x1 -= 5\n",
    "        self.pipe_x2 -= 5\n",
    "        if self.pipe_x1 < -PIPE_WIDTH:\n",
    "            self.pipe_x1 = SCREEN_WIDTH\n",
    "            self.pipe_height1 = random.randint(100, SCREEN_HEIGHT - GAP_SIZE)\n",
    "            self.score += 1\n",
    "            return True\n",
    "        elif self.pipe_x2 < -PIPE_WIDTH:\n",
    "            self.pipe_x2 = SCREEN_WIDTH\n",
    "            self.pipe_height2 = random.randint(100, SCREEN_HEIGHT - GAP_SIZE)\n",
    "            self.score += 1\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "    def check_collisions(self, bird):\n",
    "        collision_occurred = False\n",
    "        if bird.y > SCREEN_HEIGHT or bird.y < -BIRD_SIZE:\n",
    "            collision_occurred = True\n",
    "        if bird.x + BIRD_SIZE > self.pipe_x1 and bird.x < self.pipe_x1 + PIPE_WIDTH:\n",
    "            if bird.y < self.pipe_height1 or bird.y + BIRD_SIZE > self.pipe_height1 + GAP_SIZE:\n",
    "                collision_occurred = True\n",
    "        elif bird.x + BIRD_SIZE > self.pipe_x2 and bird.x < self.pipe_x2 + PIPE_WIDTH:\n",
    "            if bird.y < self.pipe_height2 or bird.y + BIRD_SIZE > self.pipe_height2 + GAP_SIZE:\n",
    "                collision_occurred = True\n",
    "        return collision_occurred\n",
    "\n",
    "    def process_game_events(self):\n",
    "        global moved\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                return True\n",
    "            if event.type == pygame.KEYDOWN:\n",
    "                if event.key == pygame.K_UP:\n",
    "                    self.bird.flap()\n",
    "                    moved = True\n",
    "        return False\n",
    "\n",
    "    def draw_game(self, birds):\n",
    "        global SCREEN\n",
    "        self.screen.blit(bg_img, (0,0))\n",
    "        for bird in birds:\n",
    "            #pygame.draw.rect(self.screen, (255, 255, 255,10), (bird.x, bird.y, BIRD_SIZE, BIRD_SIZE))\n",
    "            self.screen.blit(bird_img, (bird.x,bird.y))\n",
    "        #pygame.draw.rect(self.screen, (255, 255, 255), (self.pipe_x1, 0, PIPE_WIDTH, self.pipe_height1))\n",
    "        #pygame.draw.rect(self.screen, (255, 255, 255), (self.pipe_x1, self.pipe_height1 + GAP_SIZE, PIPE_WIDTH, SCREEN_HEIGHT - self.pipe_height1 - GAP_SIZE))\n",
    "        self.screen.blit(pipe_img, (self.pipe_x1, self.pipe_height1 + GAP_SIZE))\n",
    "        self.screen.blit(pygame.transform.flip(pipe_img, False, True), (self.pipe_x1, self.pipe_height1 - PIPE_HEIGHT))\n",
    "        \n",
    "        #pygame.draw.rect(self.screen, (255, 255, 255), (self.pipe_x2, 0, PIPE_WIDTH, self.pipe_height2))\n",
    "        #pygame.draw.rect(self.screen, (255, 255, 255), (self.pipe_x2, self.pipe_height2 + GAP_SIZE, PIPE_WIDTH, SCREEN_HEIGHT - self.pipe_height2 - GAP_SIZE))\n",
    "        self.screen.blit(pipe_img, (self.pipe_x2, self.pipe_height2 + GAP_SIZE))\n",
    "        self.screen.blit(pygame.transform.flip(pipe_img, False, True), (self.pipe_x2, self.pipe_height2 - PIPE_HEIGHT))\n",
    "\n",
    "        pygame.display.update()\n",
    "\n",
    "    def run(self):\n",
    "        # initial screen\n",
    "        if VISUALISE: \n",
    "            self.draw_game([self.bird])\n",
    "        intial_running = True\n",
    "        while intial_running:\n",
    "            for event in pygame.event.get():\n",
    "                if event.type == pygame.QUIT:\n",
    "                    pygame.quit()\n",
    "                    exit(0)\n",
    "                if event.type == pygame.KEYDOWN:\n",
    "                    intial_running = False\n",
    "        # Game loop\n",
    "        while True:\n",
    "            # if quit signal returned, end game \n",
    "            if self.process_game_events(): break\n",
    "            # move game entities\n",
    "            self.bird.move_bird()\n",
    "            self.move_pipes()\n",
    "            # if collision occurred, end game\n",
    "            if self.check_collisions(self.bird): break\n",
    "            # Update display\n",
    "            if VISUALISE: self.draw_game([self.bird])\n",
    "            pygame.display.update()\n",
    "            self.clock.tick(MAX_FRAME_RATE)\n",
    "        print(self.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e55cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_network():\n",
    "    local_dir = os.path.abspath('')\n",
    "    config_path = os.path.join(local_dir, \"config.txt\")\n",
    "    config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction, neat.DefaultSpeciesSet, neat.DefaultStagnation, config_path)\n",
    "    with open(\"best.pickle\", \"rb\") as f:\n",
    "        genome = pickle.load(f)\n",
    "    return neat.nn.FeedForwardNetwork.create(genome, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277b2fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# play the game\n",
    "pygame.init()\n",
    "screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "game_instance = Game(screen)\n",
    "network = load_network()\n",
    "game_instance.run()\n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa00c1e",
   "metadata": {},
   "source": [
    "The RL task is to train the bird to achieve a high score and be able to fly perfectly through the pipes. When training reinforcement learning models in game-playing capabilities, a common trend is to utilise genetic models such as the NEAT algorithm, Experience replay models like Deep Q-Learning or model-free methods such as Q-Learning. Many of these methods require a direct tap into the variables of the game and as a result, rely on self-implementations that dont directly reflect the true state of the game. As a result, the aim of this paper is to implement a model that utilises CNN classification techniques to identify game objects, and provide data to another algorithm for Reinforced Learning. This should allow the model to be used on any implementation of Flappy Bird, regardless of gamescreen size or particular game assets, giving the implementation an edge over other models. From prior research, it has been hypothesised that the Deep Q-Learning model, with its capability to generalise actions over large datasets will be the most suitable approach to combine with this CNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a17ad6",
   "metadata": {},
   "source": [
    "# Exploratory Analysis of Data or RL Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4f1892",
   "metadata": {},
   "source": [
    "The RL task relies on having input information to base its decision on. In this game, the input data values are:\n",
    "\n",
    "- The Bird's x coordinate\n",
    "- The Bird's y coordinate\n",
    "- The first pipe's x coordinate\n",
    "- The first pipe's y coordinate\n",
    "- The second pipe's x coordinate\n",
    "- The second pipe's y coordinate\n",
    "\n",
    "The output of a given model will be the decision on whether to flap or not (a boolean value).\n",
    "\n",
    "The constants for this environment include:\n",
    "Scaled game\n",
    "- Screen width: 288\n",
    "- Screen height: 512\n",
    "- Vertical gap between pipes: 100\n",
    "- Pipe velocity: 4\n",
    "\n",
    "Non-scaled game\n",
    "- Screen width: 550\n",
    "- Screen height: 850\n",
    "- Vertical gap between pipes: 150\n",
    "- Pipe velocity: 4\n",
    "\n",
    "Whilst most models for games are fed this data directly in the program, the project will also use a CNN approach which only utilises the screen pixels and no direct data. The CNN model will approximate the input data values from above and feed them into a Deep Q-Learning model. For this type of model, preprocessing is applied on the images of the game. This data is generated by running a model from the Q-Learning method and saving each frame as a tensor as well as the corresponding input data values (defined above). Each frame of the game will have 3 channels corresonding to red, blue, and green. In pygame, each of these values range from 0 to 255 and so to standardise the values, each of the channel values is divided by 255. The training data values are also normalised by dividing by either the screen height or width depending on which data value it is. For example, the bird's y-coordinate is in the range of 0 to SCREEN_HEIGHT and so it is divided by the SCREEN_HEIGHT to give a normalised value between 0 and 1.\n",
    "\n",
    "A diagram showing the preprocessing of the image is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aea63a",
   "metadata": {},
   "source": [
    "<img src=\"imgs/preprocessing.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5ba7be",
   "metadata": {},
   "source": [
    "# Models and/or Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b899be",
   "metadata": {},
   "source": [
    "\n",
    "### CNN Model Structure\n",
    "- Convolution layer with 32 filters and kernel size 5\n",
    "- Maxpooling kernel size 10\n",
    "- Convolution layer with 64 filters and kernel size 5\n",
    "- Fully connected layer with 100 hidden nodes\n",
    "- Output layer with 3 nodes corresponding to the data values\n",
    "\n",
    "All layers have a RELU activation except the output layer which has a sigmoid activation. Each of the 3 output values are between 0 and 1 due to the sigmoid activation.\n",
    "\n",
    "### Deep Q-Learning Model Structure\n",
    "- Add \n",
    "- Our \n",
    "- Final\n",
    "- Structure\n",
    "\n",
    "### Combining These Models\n",
    "To combine the models, the CNN outputs (Bird x, Bird y, First Pipe x, First Pipe y, Second Pipe x, Second pipe y), will be used as inputs directly into the Deep Q-Learning Model. Note that due to velocity being difficult to track given the research time, it was decided to simply take velocity straight from the game values. There are a few ways this could have been implemented. One way is to change the rotational componenent of the bird image depending on its velocity. Another way would be to input a sequence of images rather than a single image, for example joining 5 successive frames together into a larger image which would allow the CNN to see the change in the birds position, allowing it to infer its velocity.\n",
    "\n",
    "The values of the outputs of the CNN are in the range of 0 to 1. So, they are scaled back up to the screen size so that they can provide the coordinate positions for the input data values. These coordinates are then fed into the Q-Learning model creating a CNN Q-Learning model. A model that identifies pixel values through a CNN, uses these as inputs for a Deep Q-Learning model, which finally outputs the \"Flap\" or \"No Flap\" condition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e02880",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349c1a11",
   "metadata": {},
   "source": [
    "We need to basically just put all of the metrics here, and what they are."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822ed5fd",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3e8c96",
   "metadata": {},
   "source": [
    "Talk about each of the results, the trends that are there, what they could mean. Etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
